{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FrozenLake 8x8 solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import gym\n",
    "from gym import wrappers\n",
    "import random\n",
    "import numpy as np\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "import logging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-04-10 15:32:08,893] Making new env: FrozenLake-v0\n"
     ]
    }
   ],
   "source": [
    "env = gym.make(\"FrozenLake-v0\")\n",
    "\n",
    "n_states = env.observation_space.n\n",
    "n_actions = env.action_space.n\n",
    "\n",
    "# constants, hyperparams\n",
    "episode_max_steps = 1000\n",
    "evaluate_n_times = 100\n",
    "crossover_p = 0.5\n",
    "mutation_p = 0.1\n",
    "decay_mutation = 0.99\n",
    "\n",
    "n_epoches = 100\n",
    "pool_size = 100\n",
    "n_crossovers = 50\n",
    "n_mutations = 50\n",
    "\n",
    "recording = True\n",
    "recording_dir = \"result\"\n",
    "\n",
    "if recording:\n",
    "    # shut up logger\n",
    "    gym.logger.setLevel(logging.ERROR)\n",
    "    env = wrappers.Monitor(env, recording_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_random_policy():\n",
    "    return np.random.choice(n_actions, size=n_states)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def sample_reward(env, policy):\n",
    "    s = env.reset()\n",
    "    total_reward = 0\n",
    "    for _ in range(episode_max_steps):\n",
    "        s, reward, is_done, _ = env.step(policy[s])\n",
    "        total_reward += reward\n",
    "        if is_done:\n",
    "            break\n",
    "    return total_reward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def evaluate(policy, n_times=evaluate_n_times):\n",
    "    rewards = [sample_reward(env, policy) for _ in range(n_times)]\n",
    "    return float(np.mean(rewards))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def crossover(policy1, policy2, p):\n",
    "    \"\"\"\n",
    "    for each state, with probability p take action from policy1, else policy2\n",
    "    \"\"\"\n",
    "    idx = np.random.rand(len(policy1)) < p\n",
    "    return np.choose(idx, [policy1, policy2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def mutation(policy, p):\n",
    "    \"\"\"\n",
    "    for each state, with probability p replace action with random action\n",
    "    Tip: mutation can be written as crossover with random policy\n",
    "    \"\"\"\n",
    "    return crossover(get_random_policy(), policy, p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# initialization\n",
    "pool = [get_random_policy() for _ in range(pool_size)]\n",
    "scores = [evaluate(p) for p in pool]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d46520d3a500465e95e6b046e8e2074c"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0: Best score: 0.21, mutation_p: 0.100000\n",
      "Epoch 1: Best score: 0.21, mutation_p: 0.099000\n",
      "Epoch 2: Best score: 0.23, mutation_p: 0.098010\n",
      "Epoch 3: Best score: 0.30, mutation_p: 0.097030\n",
      "Epoch 4: Best score: 0.30, mutation_p: 0.096060\n",
      "Epoch 5: Best score: 0.30, mutation_p: 0.095099\n",
      "Epoch 6: Best score: 0.30, mutation_p: 0.094148\n",
      "Epoch 7: Best score: 0.67, mutation_p: 0.093207\n",
      "Epoch 8: Best score: 0.67, mutation_p: 0.092274\n",
      "Epoch 9: Best score: 0.72, mutation_p: 0.091352\n",
      "Epoch 10: Best score: 0.73, mutation_p: 0.090438\n",
      "Epoch 11: Best score: 0.73, mutation_p: 0.089534\n",
      "Epoch 12: Best score: 0.75, mutation_p: 0.088638\n",
      "Epoch 13: Best score: 0.77, mutation_p: 0.087752\n",
      "Epoch 14: Best score: 0.79, mutation_p: 0.086875\n",
      "Epoch 15: Best score: 0.79, mutation_p: 0.086006\n",
      "Epoch 16: Best score: 0.79, mutation_p: 0.085146\n",
      "Epoch 17: Best score: 0.79, mutation_p: 0.084294\n",
      "Epoch 18: Best score: 0.83, mutation_p: 0.083451\n",
      "Epoch 19: Best score: 0.83, mutation_p: 0.082617\n",
      "Epoch 20: Best score: 0.83, mutation_p: 0.081791\n",
      "Epoch 21: Best score: 0.83, mutation_p: 0.080973\n",
      "Epoch 22: Best score: 0.83, mutation_p: 0.080163\n",
      "Epoch 23: Best score: 0.83, mutation_p: 0.079361\n",
      "Epoch 24: Best score: 0.83, mutation_p: 0.078568\n",
      "Epoch 25: Best score: 0.83, mutation_p: 0.077782\n",
      "Epoch 26: Best score: 0.83, mutation_p: 0.077004\n",
      "Epoch 27: Best score: 0.85, mutation_p: 0.076234\n",
      "Epoch 28: Best score: 0.85, mutation_p: 0.075472\n",
      "Epoch 29: Best score: 0.85, mutation_p: 0.074717\n",
      "Epoch 30: Best score: 0.85, mutation_p: 0.073970\n",
      "Epoch 31: Best score: 0.85, mutation_p: 0.073230\n",
      "Epoch 32: Best score: 0.85, mutation_p: 0.072498\n",
      "Epoch 33: Best score: 0.85, mutation_p: 0.071773\n",
      "Epoch 34: Best score: 0.85, mutation_p: 0.071055\n",
      "Epoch 35: Best score: 0.86, mutation_p: 0.070345\n",
      "Epoch 36: Best score: 0.86, mutation_p: 0.069641\n",
      "Epoch 37: Best score: 0.86, mutation_p: 0.068945\n",
      "Epoch 38: Best score: 0.86, mutation_p: 0.068255\n",
      "Epoch 39: Best score: 0.86, mutation_p: 0.067573\n",
      "Epoch 40: Best score: 0.86, mutation_p: 0.066897\n",
      "Epoch 41: Best score: 0.86, mutation_p: 0.066228\n",
      "Epoch 42: Best score: 0.86, mutation_p: 0.065566\n",
      "Epoch 43: Best score: 0.86, mutation_p: 0.064910\n",
      "Epoch 44: Best score: 0.86, mutation_p: 0.064261\n",
      "Epoch 45: Best score: 0.86, mutation_p: 0.063619\n",
      "Epoch 46: Best score: 0.86, mutation_p: 0.062982\n",
      "Epoch 47: Best score: 0.86, mutation_p: 0.062353\n",
      "Epoch 48: Best score: 0.86, mutation_p: 0.061729\n",
      "Epoch 49: Best score: 0.86, mutation_p: 0.061112\n",
      "Epoch 50: Best score: 0.86, mutation_p: 0.060501\n",
      "Epoch 51: Best score: 0.86, mutation_p: 0.059896\n",
      "Epoch 52: Best score: 0.86, mutation_p: 0.059297\n",
      "Epoch 53: Best score: 0.86, mutation_p: 0.058704\n",
      "Epoch 54: Best score: 0.86, mutation_p: 0.058117\n",
      "Epoch 55: Best score: 0.86, mutation_p: 0.057535\n",
      "Epoch 56: Best score: 0.86, mutation_p: 0.056960\n",
      "Epoch 57: Best score: 0.86, mutation_p: 0.056391\n",
      "Epoch 58: Best score: 0.86, mutation_p: 0.055827\n",
      "Epoch 59: Best score: 0.86, mutation_p: 0.055268\n",
      "Epoch 60: Best score: 0.86, mutation_p: 0.054716\n",
      "Epoch 61: Best score: 0.86, mutation_p: 0.054169\n",
      "Epoch 62: Best score: 0.86, mutation_p: 0.053627\n",
      "Epoch 63: Best score: 0.86, mutation_p: 0.053091\n",
      "Epoch 64: Best score: 0.86, mutation_p: 0.052560\n",
      "Epoch 65: Best score: 0.86, mutation_p: 0.052034\n",
      "Epoch 66: Best score: 0.86, mutation_p: 0.051514\n",
      "Epoch 67: Best score: 0.86, mutation_p: 0.050999\n",
      "Epoch 68: Best score: 0.86, mutation_p: 0.050489\n",
      "Epoch 69: Best score: 0.86, mutation_p: 0.049984\n",
      "Epoch 70: Best score: 0.86, mutation_p: 0.049484\n",
      "Epoch 71: Best score: 0.86, mutation_p: 0.048989\n",
      "Epoch 72: Best score: 0.86, mutation_p: 0.048499\n",
      "Epoch 73: Best score: 0.86, mutation_p: 0.048014\n",
      "Epoch 74: Best score: 0.86, mutation_p: 0.047534\n",
      "Epoch 75: Best score: 0.86, mutation_p: 0.047059\n",
      "Epoch 76: Best score: 0.86, mutation_p: 0.046588\n",
      "Epoch 77: Best score: 0.86, mutation_p: 0.046122\n",
      "Epoch 78: Best score: 0.86, mutation_p: 0.045661\n",
      "Epoch 79: Best score: 0.86, mutation_p: 0.045204\n",
      "Epoch 80: Best score: 0.86, mutation_p: 0.044752\n",
      "Epoch 81: Best score: 0.86, mutation_p: 0.044305\n",
      "Epoch 82: Best score: 0.86, mutation_p: 0.043862\n",
      "Epoch 83: Best score: 0.86, mutation_p: 0.043423\n",
      "Epoch 84: Best score: 0.86, mutation_p: 0.042989\n",
      "Epoch 85: Best score: 0.86, mutation_p: 0.042559\n",
      "Epoch 86: Best score: 0.86, mutation_p: 0.042133\n",
      "Epoch 87: Best score: 0.86, mutation_p: 0.041712\n",
      "Epoch 88: Best score: 0.86, mutation_p: 0.041295\n",
      "Epoch 89: Best score: 0.86, mutation_p: 0.040882\n",
      "Epoch 90: Best score: 0.86, mutation_p: 0.040473\n",
      "Epoch 91: Best score: 0.86, mutation_p: 0.040068\n",
      "Epoch 92: Best score: 0.86, mutation_p: 0.039668\n",
      "Epoch 93: Best score: 0.86, mutation_p: 0.039271\n",
      "Epoch 94: Best score: 0.86, mutation_p: 0.038878\n",
      "Epoch 95: Best score: 0.86, mutation_p: 0.038490\n",
      "Epoch 96: Best score: 0.86, mutation_p: 0.038105\n",
      "Epoch 97: Best score: 0.86, mutation_p: 0.037724\n",
      "Epoch 98: Best score: 0.86, mutation_p: 0.037346\n",
      "Epoch 99: Best score: 0.86, mutation_p: 0.036973\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for epoch in tqdm(range(n_epoches)):\n",
    "    mutations = [mutation(random.choice(pool), mutation_p) \n",
    "                 for _ in range(n_mutations)]\n",
    "    crossovers = [crossover(random.choice(pool), random.choice(pool), crossover_p)\n",
    "                 for _ in range(n_crossovers)]\n",
    "    pool.extend(mutations)\n",
    "    scores.extend([evaluate(p) for p in mutations])\n",
    "    pool.extend(crossovers)\n",
    "    scores.extend([evaluate(p) for p in crossovers])\n",
    "\n",
    "    # truncate the pool\n",
    "    selected_indices = np.argsort(scores)[-pool_size:]\n",
    "    pool = [pool[i] for i in selected_indices]\n",
    "    scores = [scores[i] for i in selected_indices]\n",
    "\n",
    "    best_score = scores[-1]\n",
    "    print(\"Epoch %d: Best score: %.2f, mutation_p: %f\" % (epoch, best_score, mutation_p))\n",
    "    \n",
    "    mutation_p *= decay_mutation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "env.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://gym.openai.com/evaluations/eval_u01ZYLDmRbq5Z1rY6iPvLA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
